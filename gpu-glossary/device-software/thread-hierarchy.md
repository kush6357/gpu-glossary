---
title: Thread Hierarchy
---

![The thread hierarchy of the [CUDA programming model](/gpu-glossary/device-software/cuda-programming-model) spans from individual [threads](/gpu-glossary/device-software/thread) to [thread blocks](/gpu-glossary/device-software/thread-block) to [thread block grids](/gpu-glossary/device-software/thread-block-grid) (left), mapping onto the hardware from [CUDA Cores](/gpu-glossary/device-hardware/cuda-core) to [Streaming Multiprocessors](/gpu-glossary/device-hardware/streaming-multiprocessor) to the entire GPU (right). Modified from diagrams in NVIDIA's [CUDA Refresher: The CUDA Programming Model](https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/) and the NVIDIA [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model).](themed-image://cuda-programming-model.svg)

The thread hierarchy is a key abstraction of the [CUDA programming model](/gpu-glossary/device-software/cuda-programming-model), alongside the [memory hierarchy](/gpu-glossary/device-software/memory-hierarchy). It organizes the execution of parallel programs across multiple levels, from individual threads up to entire GPU devices.

At the lowest level are individual [threads](/gpu-glossary/device-software/thread), each executing on a single [Core](/gpu-glossary/device-hardware/cuda-core). Groups of 32 threads are organized into [warps](/gpu-glossary/device-software/warp) and execute instructions in lockstep under the control of the [Warp Scheduler](/gpu-glossary/device-hardware/warp-scheduler).

The intermediate level consists of [thread blocks](/gpu-glossary/device-software/thread-block), which are also known as [cooperative thread arrays](/device-software/cooperative-thread-array) in [PTX](/gpu-glossary/device-software/parallel-thread-execution) and [SASS](/gpu-glossary/device-software/streaming-assembler). Each [thread](/gpu-glossary/device-software/thread) has a unique identifier within its [thread block](/gpu-glossary/device-software/thread-block) via the built-in `threadIdx` variable, a 3-component vector that enables one-, two-, or three-dimensional indexing patterns. All threads within a block execute on the same [Streaming Multiprocessor (SM)](/gpu-glossary/device-hardware/streaming-multiprocessor) and can coordinate through [shared memory](/gpu-glossary/device-software/shared-memory) and the `__syncthreads()` barrier function.  

At the highest level, multiple [thread blocks](/gpu-glossary/device-software/thread-block) are organized into a [thread block grid](/gpu-glossary/device-software/thread-block-grid) that spans the entire GPU. Each [thread block](/gpu-glossary/device-software/thread-block) has its own unique identifier within the grid via the built-in `blockIdx` variable and the `blockDim` variable provides the dimensions of the [thread block](/gpu-glossary/device-software/thread-block). [Thread blocks](/gpu-glossary/device-software/thread-block) within a grid execute concurrently with no guaranteed execution order. 

This hierarchy maps directly onto the [GPU hardware](/gpu-glossary/device-hardware): [threads](/gpu-glossary/device-software/thread) execute on individual [cores](/gpu-glossary/device-hardware/core), [thread blocks](/gpu-glossary/device-software/thread-block) are scheduled onto [SMs](/gpu-glossary/device-hardware/streaming-multiprocessor), and [grids](/gpu-glossary/device-software/thread-block-grid) utilize all available [SMs](/gpu-glossary/device-hardware/streaming-multiprocessor) on the device.
